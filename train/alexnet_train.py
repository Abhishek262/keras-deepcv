"""
Train an AlexNet model with the MNIST/CIFAR10 dataset

Print model:
	python alexnet_train.py --print_model --dataset mnist

Train and save model:
	python alexnet_train.py --train_model --epochs 10 \
		--save_weights data/alexnet_mnist_trained.hdf5 \
		--dataset cifar10

Train with pretrained weights
	python alexnet_train.py --train_model --epochs 10 \
		--save_weights data/alexnet_mnist_trained.hdf5 \
		--weights data/alexnet_mnist.hdf5 \
		--dataset cifar10
"""
import sys
sys.path.append("..")

# Import model architecture and data
from models.classification import alexnet
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import rmsprop
from datasets import cifar10
from datasets import mnist

# Import other necessary packages
import numpy as np
import argparse, cv2, os
import matplotlib.pyplot as plt

def parse_args():
	"""
	Parse command line arguments.

	Parameters:
		None
	Returns:
		parser arguments
	"""
	parser = argparse.ArgumentParser(description='LeNet model')
	optional = parser._action_groups.pop()
	required = parser.add_argument_group('required arguments')
	required.add_argument('--dataset',
		dest='dataset',
		help='Choice of dataset to train model',
		choices=['mnist', 'cifar10'],
		default='mnist')
	optional.add_argument('--print_model',
		dest='print_model',
		help='Print LeNet model',
		action='store_true')
	optional.add_argument('--train_model',
		dest='train_model',
		help='Train LeNet on MNIST',
		action='store_true')
	optional.add_argument('-s', '--save_weights',
		dest='save_weights',
		help='Save the trained weights',
		default=None)
	optional.add_argument('-w', '--weights',
		dest='weights',
		help='Path to weights (hdf5) file',
		default=None)
	optional.add_argument('-e', '--epochs',
		dest='epochs',
		help='Number of epochs for training',
		type=int,
		default=20)
	optional.add_argument('--data_augmentation',
		dest='data_augmentation',
		help='Use data augmentations for input',
		action='store_true')
	parser._action_groups.append(optional)
	return parser.parse_args()

if __name__ == '__main__':
	# Command line parameters
	args = parse_args()

	# Construct AlexNet model
	if args.weights is None:
		if dataset == 'mnist':
			model = alexnet.alexnet_model(img_shape=(28, 28, 1))
		elif dataset == 'cifar10':
			model = alexnet.alexnet_model(img_shape=(32, 32, 3))
	else:
		if dataset == 'mnist':
			model = alexnet.alexnet_model(img_shape=(28, 28, 1),
					weights=args.weights)
		elif dataset == 'cifar10':
			model = alexnet.alexnet_model(img_shape=(32, 32, 3),
					weights=args.weights)

	# Print model summary
	if args.print_model:
		model.summary()

	# Compile model
	model.compile(loss='categorical_crossentropy',
		optimizer=rmsprop(lr=0.0001, decay=1e-6),
		metrics=['accuracy'])

	# Get data
	if dataset == 'mnist':
		train_data, train_labels, test_data, test_labels = mnist.get_data()
	elif dataset == 'cifar10':
		train_data, train_labels, test_data, test_labels = cifar10.get_data()

	# Train with no data augmentation
	if not args.data_augmentation:
		print('[INFO] Training the model (without data augmentation)...')
		history = model.fit(train_data, train_labels,
			batch_size=128,
			epochs=args.epochs,
			validation_data=(test_data, test_labels),
			verbose=True,
			shuffle=True)

		# Evaluate the model
		print('[INFO] Evaluating the trained model...')
		(loss, accuracy) = model.evaluate(test_data, test_labels,
			batch_size=128,
			verbose=1)
		print('[INFO] accuracy: {:.2f}%'.format(accuracy * 100))

		# Visualize training history
		draw_training_curve(history)

	# Train with data augmentation
	else:
		print('[INFO] Training the model with data augmentation...')
		# Data augmentation
		datagen = ImageDataGenerator(
			featurewise_center=False,	# set input mean to 0 over dataset
			samplewise_center=False,	# set each sample mean to 0
			featurewise_std_normalization=False,	# divide inputs by std of dataset
			samplewise_std_normalization=False,	#divide each input by its std
			zca_whitening=False,	# apply ZCA whitening
			rotation_range=0,	# randomly roate images in the range (degrees, 0 to 180)
			width_shift_range=0.1,	# randomly shift image horizontally (fraction of width)
			height_shift_range=0.1,	# randomly shift image vertically (fraction of height)
			horizontal_flip=True,	# randomly flip images horizontally
			vertical_flip=False)	# randomly flip images vertically

		# Compute std, mean, and principal components if ZCA is applied
		datagen.fit(train_data)

		# Train the data with batches generated by datagen.flow()
		history = model.fit_generator(datagen.flow(train_data, train_labels,
			batch_size=128),
			steps_per_epoch=train_data.shape[0] // 128,
			epochs=args.epochs,
			validation_data=(test_data, test_labels),
			workers=4)

		# Evaluate the model
		print('[INFO] Evalauting the trained model...')
		(loss, accuracy) = model.evaluate_generator(
			datagen.flow(train_data, train_labels,
				batch_size=128,
				shuffle=False),
			steps=test_data.shape[0] // 128,
			workers=4)
		print('[INFO] accuracy: {:.2f}%'.format(accuracy * 100))

		# Visualize training history
		if args.viz_training:
			draw.draw_training_curve(history)

	# Save model and weights
	if args.save_weights is not None:
		print('[INFO] Saving the model weights to file...')
		if not os.path.exists(os.path.dirname(args.save_weights)):
			os.path.makedirs(os.path.dirname(args.save_weights))
		if os.path.isfile(args.save_weights):
			os.remove(args.save_weights)
		model.save_weights(args.save_weights, overwrite=True)